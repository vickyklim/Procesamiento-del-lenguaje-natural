{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b1f07c31858a43ad802fa39900a7ab85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1b1ef3964604ecfae5468fa3878baf3","IPY_MODEL_45f2898438f24f0ba3a8ec03cbf202fd","IPY_MODEL_0e3c0dbb50b2463b8a1c50ad685c0edb"],"layout":"IPY_MODEL_20c4ffc9702b48bf847b0d49723714f5"}},"a1b1ef3964604ecfae5468fa3878baf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7bbe84122164b3eabdb83b9dfa0bb32","placeholder":"​","style":"IPY_MODEL_98574df5b55643698428ac1d55399f63","value":"tokenizer_config.json: 100%"}},"45f2898438f24f0ba3a8ec03cbf202fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d40853fb70e148fdb7c06997dcf8dc0e","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8bde03c99724520a1519134cc56e2e5","value":26}},"0e3c0dbb50b2463b8a1c50ad685c0edb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4885103781d34e31846c58147a703d7c","placeholder":"​","style":"IPY_MODEL_3fc90df28c84481ca42ed724ad9c2017","value":" 26.0/26.0 [00:00&lt;00:00, 1.96kB/s]"}},"20c4ffc9702b48bf847b0d49723714f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7bbe84122164b3eabdb83b9dfa0bb32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98574df5b55643698428ac1d55399f63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d40853fb70e148fdb7c06997dcf8dc0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8bde03c99724520a1519134cc56e2e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4885103781d34e31846c58147a703d7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc90df28c84481ca42ed724ad9c2017":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41669912d33f4a77ba7bf87e3eaa3718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb4724f1c398485cb9b18804481ef2eb","IPY_MODEL_7567be6b47904cd8b291a144bdcd69ae","IPY_MODEL_ad5386ab0410422daf251217a2e835be"],"layout":"IPY_MODEL_4c106a446b764d33bc7e28f0649578b0"}},"eb4724f1c398485cb9b18804481ef2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_064554a40ead47d2be41a6886144a060","placeholder":"​","style":"IPY_MODEL_5cd32086b42146dbaac55b13de5607f2","value":"vocab.json: 100%"}},"7567be6b47904cd8b291a144bdcd69ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e283ab94af2a4fcd83c31fdecdb4f7e8","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7494340a9f074963b13b4023c51e1a5b","value":1042301}},"ad5386ab0410422daf251217a2e835be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69f413d74ccb478298bfa2af7deb0bfe","placeholder":"​","style":"IPY_MODEL_5775d893713844d6b4126449950430f9","value":" 1.04M/1.04M [00:00&lt;00:00, 12.5MB/s]"}},"4c106a446b764d33bc7e28f0649578b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"064554a40ead47d2be41a6886144a060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cd32086b42146dbaac55b13de5607f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e283ab94af2a4fcd83c31fdecdb4f7e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7494340a9f074963b13b4023c51e1a5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69f413d74ccb478298bfa2af7deb0bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5775d893713844d6b4126449950430f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c1d7565f10d4660a5a96584907a3d52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89a2569ea25f45deacb019d2392e8764","IPY_MODEL_f3169d79a92c427e90d1c53e33a21e3b","IPY_MODEL_19eabafcf7cd4391918e9a9418d9a5ab"],"layout":"IPY_MODEL_7cd8b3b53a1c49c4b51d1444e44226ec"}},"89a2569ea25f45deacb019d2392e8764":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45b6093ac0a94d6fb2a820eeffa46f0a","placeholder":"​","style":"IPY_MODEL_9eb39184018d43658460a08c5ddfd34e","value":"merges.txt: 100%"}},"f3169d79a92c427e90d1c53e33a21e3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_764e6e533bac44a2bb5686770acbc9d0","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e48aff979d294b7f8cf86946c0ee9a73","value":456318}},"19eabafcf7cd4391918e9a9418d9a5ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd090f0aa0374814b916c13284a89c2a","placeholder":"​","style":"IPY_MODEL_f32d657a64484049bfbce3efe955e12a","value":" 456k/456k [00:00&lt;00:00, 2.30MB/s]"}},"7cd8b3b53a1c49c4b51d1444e44226ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b6093ac0a94d6fb2a820eeffa46f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb39184018d43658460a08c5ddfd34e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764e6e533bac44a2bb5686770acbc9d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e48aff979d294b7f8cf86946c0ee9a73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd090f0aa0374814b916c13284a89c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32d657a64484049bfbce3efe955e12a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17efce8377404a9c867bd679fc26ac45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64ffbb742478475ab4495f02647cb5d6","IPY_MODEL_fb1d7043ae2c43d29385802958609c9f","IPY_MODEL_515d9b6ec7374345b4e398facfcd9a2b"],"layout":"IPY_MODEL_26aecb05222947baba268cb4016fb4ae"}},"64ffbb742478475ab4495f02647cb5d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc04a146e815494086a4f0196c75cab4","placeholder":"​","style":"IPY_MODEL_100fd813d7da4ce189a7ed0be62cbde2","value":"tokenizer.json: 100%"}},"fb1d7043ae2c43d29385802958609c9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dcd435540a94d47b7c9364bd3a311cc","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4b3dee0affd41dba9ab8e29a740a3a7","value":1355256}},"515d9b6ec7374345b4e398facfcd9a2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a47357be2524be6877c5ce0c90d52a0","placeholder":"​","style":"IPY_MODEL_bbe5c332d91d4e589b990e975ed834a6","value":" 1.36M/1.36M [00:00&lt;00:00, 33.0MB/s]"}},"26aecb05222947baba268cb4016fb4ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc04a146e815494086a4f0196c75cab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100fd813d7da4ce189a7ed0be62cbde2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dcd435540a94d47b7c9364bd3a311cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b3dee0affd41dba9ab8e29a740a3a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a47357be2524be6877c5ce0c90d52a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe5c332d91d4e589b990e975ed834a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b2b96b5d9cd4546afa00e0ca335651e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ea54391747c4f8ba836202ee4a54ec4","IPY_MODEL_079c99bdc359469c8d4a0a4a29056456","IPY_MODEL_090267c0f1844e0892bacad6eb4eb258"],"layout":"IPY_MODEL_47c28ddd159c438b87dff55687168106"}},"2ea54391747c4f8ba836202ee4a54ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1b89fa489443c784903975e7cb0d9e","placeholder":"​","style":"IPY_MODEL_414cd20993b8426b8fbb0a4d1d349faf","value":"config.json: 100%"}},"079c99bdc359469c8d4a0a4a29056456":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1581fc068cc548bbadd30f6d6d6cd589","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89aa0856c8584e43be2ba7d34589fd6f","value":665}},"090267c0f1844e0892bacad6eb4eb258":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c483372d341a4be5b2aff7ea7d932784","placeholder":"​","style":"IPY_MODEL_9799ca367e4544ef9e287a58ce2c3b7c","value":" 665/665 [00:00&lt;00:00, 51.2kB/s]"}},"47c28ddd159c438b87dff55687168106":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1b89fa489443c784903975e7cb0d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"414cd20993b8426b8fbb0a4d1d349faf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1581fc068cc548bbadd30f6d6d6cd589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89aa0856c8584e43be2ba7d34589fd6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c483372d341a4be5b2aff7ea7d932784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9799ca367e4544ef9e287a58ce2c3b7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29073456a373495d9f9309888308af75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39c22d199bdb4e0f829de9f749e873cc","IPY_MODEL_db218e7c9527436380d4bbdbe74b6c65","IPY_MODEL_aa704158b8854d95bf1ff5f02e7640fd"],"layout":"IPY_MODEL_09ae1666fedd4e08b2882ded1ca132c9"}},"39c22d199bdb4e0f829de9f749e873cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4d25b87cca742b7a8b1af5e6dd86fac","placeholder":"​","style":"IPY_MODEL_97b0351b2c604308a5363ce6a3568e1a","value":"model.safetensors: 100%"}},"db218e7c9527436380d4bbdbe74b6c65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb1f66127ae64876b4780cfb30c26657","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bbce1489e49446cb5a2fa8be105a978","value":548105171}},"aa704158b8854d95bf1ff5f02e7640fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2713feab3aba409691ed10f4767eb704","placeholder":"​","style":"IPY_MODEL_33080c272fed4beca86a4616eedbd9c5","value":" 548M/548M [00:02&lt;00:00, 230MB/s]"}},"09ae1666fedd4e08b2882ded1ca132c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4d25b87cca742b7a8b1af5e6dd86fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97b0351b2c604308a5363ce6a3568e1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb1f66127ae64876b4780cfb30c26657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bbce1489e49446cb5a2fa8be105a978":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2713feab3aba409691ed10f4767eb704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33080c272fed4beca86a4616eedbd9c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"162542ca57384ddbb3b11f1228b9970d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_032ec9ee6c0e4f608cc1f0ab21de62e7","IPY_MODEL_b688f440101848b6a0a8bd134cad0ade","IPY_MODEL_5c1cbaa9f24a4720a58958873ef8d02e"],"layout":"IPY_MODEL_4cd031d9db914fe389d8c356b5e8e5bb"}},"032ec9ee6c0e4f608cc1f0ab21de62e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f8ddbd561b14147a4f69c91794b5b89","placeholder":"​","style":"IPY_MODEL_866ee771ea224200a7d47ad1f450a4e1","value":"generation_config.json: 100%"}},"b688f440101848b6a0a8bd134cad0ade":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa59d916fe1d43098f7b9f5caf2a13f5","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef9e111e6b114221823fb4339b57f45a","value":124}},"5c1cbaa9f24a4720a58958873ef8d02e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ab8e5a8f724a16bf0351945a2ebaf4","placeholder":"​","style":"IPY_MODEL_e2d899b08f1f4099a4347e1400b63624","value":" 124/124 [00:00&lt;00:00, 8.08kB/s]"}},"4cd031d9db914fe389d8c356b5e8e5bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8ddbd561b14147a4f69c91794b5b89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866ee771ea224200a7d47ad1f450a4e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa59d916fe1d43098f7b9f5caf2a13f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef9e111e6b114221823fb4339b57f45a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6ab8e5a8f724a16bf0351945a2ebaf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d899b08f1f4099a4347e1400b63624":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["pip install transformers torch datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HMEkNV9UF_o","executionInfo":{"status":"ok","timestamp":1732480100597,"user_tz":180,"elapsed":15799,"user":{"displayName":"Malena Alamo","userId":"14613785634686341446"}},"outputId":"d7cf5669-5b81-4d61-bd0d-db76d3425771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import random\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoCIxcNDUpV_","executionInfo":{"status":"ok","timestamp":1732551296021,"user_tz":180,"elapsed":65082,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"bca3d28d-c2f7-4d05-ac91-48388aa76a75"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"metadata":{"id":"xI_UFB7rVfvz","executionInfo":{"status":"ok","timestamp":1732551301050,"user_tz":180,"elapsed":313,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["#Pruebas (ignorar)\n"],"metadata":{"id":"ThFOQo09s-fL"}},{"cell_type":"code","source":["def generar_cancion(model, tokenizer, input_text, max_length=100):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","input_text = \"Amor eterno\"\n","cancion = generar_cancion(model, tokenizer, input_text, max_length=1000)\n","print(\"Canción generada:\\n\", cancion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3v_sD346bA83","executionInfo":{"status":"ok","timestamp":1732390208648,"user_tz":180,"elapsed":11046,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"266fe74a-2515-4849-c316-33bb54319f31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno\n","Démigo, no esta que aunque un mejor de tiene (Y) y esperando el mínde en la vida tú lo franca'', pienso podrás por cuenta yo siempre día: ¿quieró?¡Quirte quilez conno todas mi amores te llama'? Ángel noche seguido aquiendo ya sabes las pensos perderon-de razón desarmeñanas - llegado si le escribuente lloramador al cada otro bataña\n"]}]},{"cell_type":"markdown","source":["Chequear que uso la GPU"],"metadata":{"id":"vTZ8nNNVYPQw"}},{"cell_type":"code","source":["import torch\n","print(torch.cuda.is_available())  # Debería devolver True\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8Z0KyuWYOKT","executionInfo":{"status":"ok","timestamp":1732533794821,"user_tz":180,"elapsed":455,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"323312a7-f544-4817-b023-a3f5998fad60"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["# 1. Cargar el dataset desde Google Drive\n","ruta_archivo = '/content/drive/MyDrive/NLP/TP final/canciones_artistas.csv'\n","df = pd.read_csv(ruta_archivo)\n","\n","\n","# 2. Selección de artistas y porcentajes\n","def seleccionar_datos(df, distribucion):\n","    artistas_seleccionados = {k: v for k, v in distribucion.items() if v > 0}\n","    letras_seleccionadas = []\n","    for artista, porcentaje in artistas_seleccionados.items():\n","        letras_artista = df[df['artista'] == artista]['cancion'].tolist()\n","        n_seleccionadas = int(len(letras_artista) * porcentaje / 100)\n","        letras_seleccionadas.extend(random.sample(letras_artista, n_seleccionadas))\n","    return letras_seleccionadas\n","\n","# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 0,\n","    \"spinetta\": 100,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"dataset_train.txt\",\n","    block_size=128\n",")\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset\n",")\n","\n","trainer.train()\n","\n","\n","# Mover el modelo a la GPU\n","model = model.to(\"cuda\")\n","\n","def generar_cancion(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.4,                # Aleatoriedad en la generación\n","        top_k=100,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","input_text = \"Amor eterno\"\n","cancion = generar_cancion(model, tokenizer, input_text, max_length=1000)\n","print(\"Canción generada:\\n\", cancion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"6izSsRMLiSwp","executionInfo":{"status":"ok","timestamp":1732533858374,"user_tz":180,"elapsed":61500,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"99321bf7-f6da-40a0-a9ca-303095b2d9ed"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [180/180 00:41, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno\n","Entre nombres no vez de mi vida, mí y espera en la luz\" (Y)\n","\n","Hoy se habrándote ya te abierto por el mundial del Sol. Donde al fin amor año los bienos que estar tu cielso hastan aquel hagólo sin nunca con las horas otra un parediré despicierdo (\"y yo me entendiar\") soprás comunidad ademarcín para tus sueñales desde lo capitán atoloso arbol duerma dolor voce durante? Fermes su gran franca farro allende haría ser azul leche sus fuentros voycerme recurvemente volver acabrirando asción verdad apareces tal querer vens encontrarillo solo lluvia son floresque este crepor distancia puestra largipara aleja secura caen sedate rezo bracerla hayendo todalo podesta calligliene cosociado detribero ancon va edificio preguntamentena cuanto corazones altaria nuestro jardin tan colectivitar hojano piercido establira escuchane cruposal andriya diaba panilla galore siudadora canchera descubruza instantedecito finalizionario silviage rientras imprensa maquillojita destino gris marques emprenderba tienda espana mirador niña malle piego felicitaciada misandés decidades tristejas moridas carne blanco \"guacamire\", temprani na barrera salvo subiejo irún perdueda dormente lloreno génaga indianna diamantico da pelodede medios mancha lobao satrapismo color érbolo monte solitudina rayon brillaron viagra rojarno dirijda evaldale invennuovo sagrandavigo engardelevata reliquenta dedupe golperer somberluhiza besoin vas orto tierredue buccormosa agua tencomparajuelva antropologasta frentaste restrecarte igual cortoballitan dos pensanta vertebra fuega tendercuerpo jamajo era hasbro chocolativo ardoria debetodo mentremesa valenciano hermos libertama revista propria livraciembre travailome penelope fegasse zambardo marchiga melica bebe quiens errantistas palomares pecho californame garçons démarste dinarrêmes plantamar ángela cantalla mismander eneràntima pasoguro parmella gestaltiva colloquium ne vestibula real sangral terminacion confidencial une robisa hijabi partez-proprizedete muchacha locustrum curias inquietta gnoches guerrasio vagablilo venturan droves cristatos nos libris punnos menotires domingutulo senco murmur vocivenation rouge hallamo ambacio vendrero human habitations basidiose ensignadas dentarguedevices tentax cerradarse terrestrammas querarios pluceta soximo botellanos hospice sur revoluciuy historiera sentayago ramblings muzermo castillas busheltar ellivervas fulgorfiche trilegiantisiérrito vacuo vanessa camortaro rentear...\n"]}]},{"cell_type":"code","source":["    def generar_cancion(model, tokenizer, input_text, max_length=1000):\n","        inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","        outputs = model.generate(\n","            inputs,\n","            max_length=max_length,          # Longitud máxima del texto\n","            num_return_sequences=1,         # Número de secuencias a generar\n","            temperature=0.4,                # Aleatoriedad en la generación\n","            top_k=100,                       # Considera solo los 50 tokens más probables\n","            top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","            repetition_penalty=1.5,         # Penaliza repeticiones\n","            do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","        )\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"8U1l-cFsmpzA","executionInfo":{"status":"ok","timestamp":1732533878241,"user_tz":180,"elapsed":3,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Aca con los 4 al mismo tiempo"],"metadata":{"id":"-_mfVzlNrdbw"}},{"cell_type":"code","source":["# 2. Selección de artistas y porcentajes\n","def seleccionar_datos(df, distribucion):\n","    artistas_seleccionados = {k: v for k, v in distribucion.items() if v > 0}\n","    letras_seleccionadas = []\n","    for artista, porcentaje in artistas_seleccionados.items():\n","        letras_artista = df[df['artista'] == artista]['cancion'].tolist()\n","        n_seleccionadas = int(len(letras_artista) * porcentaje / 100)\n","        letras_seleccionadas.extend(random.sample(letras_artista, n_seleccionadas))\n","    return letras_seleccionadas\n","\n","def generar_cancion(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.4,                # Aleatoriedad en la generación\n","        top_k=100,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"],"metadata":{"id":"JJdenc7rrZxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Cargar el dataset desde Google Drive\n","ruta_archivo = '/content/drive/MyDrive/NLP/TP final/canciones_artistas.csv'\n","df = pd.read_csv(ruta_archivo)\n","\n","# Lista de artistas para iterar\n","artistas = [\"spinetta\", \"tini\", \"callejero\", \"dillom\"]\n","\n","# Configuración de entrenamiento para cada artista\n","for artista in artistas:\n","    print(f\"Entrenando modelo con canciones de: {artista}\")\n","\n","    # Seleccionar las canciones del artista actual\n","    distribucion = {a: 100 if a == artista else 0 for a in artistas}\n","    letras_seleccionadas = seleccionar_datos(df, distribucion)\n","\n","    # Guardar las letras seleccionadas en un archivo de texto\n","    with open(\"dataset_train.txt\", \"w\", encoding=\"utf-8\") as f:\n","        f.write(\"\\n\".join(letras_seleccionadas))\n","\n","    # Preparar el dataset para el entrenamiento\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","    train_dataset = TextDataset(\n","        tokenizer=tokenizer,\n","        file_path=\"dataset_train.txt\",\n","        block_size=128\n","    )\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=False\n","    )\n","\n","    # Configurar y entrenar el modelo\n","    training_args = TrainingArguments(\n","        output_dir=f\"./gpt2-finetuned-{artista}\",\n","        overwrite_output_dir=True,\n","        num_train_epochs=10,\n","        per_device_train_batch_size=4,\n","        save_steps=10_000,\n","        save_total_limit=2,\n","        prediction_loss_only=True,\n","        report_to=\"none\"  # Desactiva W&B\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        data_collator=data_collator,\n","        train_dataset=train_dataset\n","    )\n","\n","    trainer.train()\n","\n","    # Mover el modelo a la GPU\n","    model = model.to(\"cuda\")\n","\n","\n","    # Generar una canción para el artista actual\n","    print(f\"Generando canción para: {artista}\")\n","    input_text = \"Amor eterno\"\n","    cancion = generar_cancion(model, tokenizer, input_text, max_length=300)\n","    print(f\"Canción generada para {artista}:\\n{cancion}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":968},"id":"lgAjZpu5mTEY","executionInfo":{"status":"error","timestamp":1732393358170,"user_tz":180,"elapsed":99156,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"54c17af0-9755-4b2c-db73-dcca36278807"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entrenando modelo con canciones de: spinetta\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [180/180 00:38, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["Generando canción para: spinetta\n","Canción generada para spinetta:\n","Amor eterno\n","Yo si nunca la nena sin soledad, el mundial de sueño. (Ya no es que será) Sol dulce vidé nos volver a las llevas del cielon y acuerdo al fin du paz\n","\n","Entrenando modelo con canciones de: tini\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [180/180 00:42, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Generando canción para: tini\n","Canción generada para tini:\n","Amor eterno\n","Yo si nunca la nena sin soledad, el mundial de sueño. (Ya no es que será) Sol dulce vidé nos volver a las llevas del cielon y acuerdo al fin du paz\n","\n","Entrenando modelo con canciones de: callejero\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='56' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 56/180 00:09 < 00:21, 5.66 it/s, Epoch 3.06/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b9e92686ad42>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Mover el modelo a la GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2124\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2484\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m                     ):\n\u001b[1;32m   2488\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["ruta_archivo = '/content/drive/MyDrive/NLP/TP final/canciones_artistas.csv'\n","df = pd.read_csv(ruta_archivo)\n","\n","\n","# 2. Selección de artistas y porcentajes\n","def seleccionar_datos(df, distribucion):\n","    artistas_seleccionados = {k: v for k, v in distribucion.items() if v > 0}\n","    letras_seleccionadas = []\n","    for artista, porcentaje in artistas_seleccionados.items():\n","        letras_artista = df[df['artista'] == artista]['cancion'].tolist()\n","        n_seleccionadas = int(len(letras_artista) * porcentaje / 100)\n","        letras_seleccionadas.extend(random.sample(letras_artista, n_seleccionadas))\n","    return letras_seleccionadas\n","\n","# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 100,\n","    \"callejero\": 0,\n","    \"spinetta\": 0,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"dataset_train.txt\",\n","    block_size=128\n",")\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset\n",")\n","\n","trainer.train()\n","\n","\n","# Mover el modelo a la GPU\n","model = model.to(\"cuda\")\n","\n","def generar_cancion(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.4,                # Aleatoriedad en la generación\n","        top_k=100,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","input_text = \"Amor eterno\"\n","cancion = generar_cancion(model, tokenizer, input_text, max_length=1000)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"wz5mGVqZo35G","executionInfo":{"status":"ok","timestamp":1732392563352,"user_tz":180,"elapsed":56465,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"8b074605-1138-49cc-d296-0ca0da00b344"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [180/180 00:46, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno\n","Entiendes en el mundial de vivir la espana, saldará del suerte. (Ya no es un hombre)\n","\n","¿Que estoye al fin? Sol que me niño donde amanecuerdo nena hasten aquí por cielos ya tambien a las horas y nunca cosando con tu soledad! Hasta más llegadas se aparecido yo ojate comunidas atalán ademarcín para lo encontrarólo sin vez venida todos los guerrones... Dios enticidades despobrirément asociado destino allende mi podría verdes cuatro son quierrantano te arrepentire este boca acaba azulce blancoso securosario hoque aleja desde crecerno solo volvermejo). Nunquie escribara caesi hablor duviendo pieperidad cruces harabazón durante leche nuestra puistén puedome diagrafia gran abandango anelillo ser tempracio talaga panza distionale il fermito frutigo sublanta rayonzo callejas reba manojiste canciarte llorajo tan rajatira bracerla finalizada.) Fuego fue sueñosa era tenera salve si pecurritol establis silencio tiene sus peligros flores da diamantes oreste piernas mirador parés recurrer une morgues antebellarios seduces felix prendote marques rosa lluvia precisayro nos correntras carne transformados ensnaredda voipudaron mis sangria descartita detallacienda mentura voyage sur les livres oracionistas perma relacias colectivo ) Betrayeda debiere golpemos decisiaria dediar agua tierri grisa farina restoria gente construcci monomolo locavità andréna altarpensima largescence hasy imprediciònguez callesa vasilla ,gujaramodo irreguidata confidençalo alas infernales jardin dos pensora cortez mismprender árbade qui va errandaro somercore dormitariano brillianya malgorica vertebra lobula cantiga medially edificient partugar muchacha castillane chaste vacuo dentero individuelvo écosimo sentimentary fuoco human vocations travúntrera maestro pasillas colorña cumpluzual haycha ventremodijede démarcilmo vestibule sacrificiembre droga herder emporium energetiza pedota satrapoda vaginas gestaltiva colloquiamantella terminus valorem cerrito punto elegietude ).\n"]}]},{"cell_type":"markdown","source":["# Generando canciones de cada artista\n","\n"],"metadata":{"id":"iwPVVCAMslIl"}},{"cell_type":"code","source":["# 1. Cargar el dataset desde Google Drive\n","ruta_archivo = '/content/drive/MyDrive/NLP/TP final/canciones_artistas.csv'\n","df = pd.read_csv(ruta_archivo)\n","\n","\n","# 2. Selección de artistas y porcentajes\n","def seleccionar_datos(df, distribucion):\n","    artistas_seleccionados = {k: v for k, v in distribucion.items() if v > 0}\n","    letras_seleccionadas = []\n","    for artista, porcentaje in artistas_seleccionados.items():\n","        letras_artista = df[df['artista'] == artista]['cancion'].tolist()\n","        n_seleccionadas = int(len(letras_artista) * porcentaje / 100)\n","        letras_seleccionadas.extend(random.sample(letras_artista, n_seleccionadas))\n","    return letras_seleccionadas\n","\n"],"metadata":{"id":"w39T-RkAsoG6","executionInfo":{"status":"ok","timestamp":1732551332585,"user_tz":180,"elapsed":1021,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df[df['artista'] == artista]['cancion']"],"metadata":{"id":"Rc2BrT8jIugO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Spinetta"],"metadata":{"id":"TI7KXV-T0tC6"}},{"cell_type":"code","source":["def generar_cancion_spinetta(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.4,                # Aleatoriedad en la generación\n","        top_k=100,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"_xQs6Oem0DzF","executionInfo":{"status":"ok","timestamp":1732534063435,"user_tz":180,"elapsed":310,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 0,\n","    \"spinetta\": 100,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas_spinetta = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_spinetta.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_spinetta))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_spinetta = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_spinetta = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_spinetta = TextDataset(\n","    tokenizer=tokenizer_spinetta,\n","    file_path=\"dataset_train_spinetta.txt\",\n","    block_size=128\n",")\n","data_collator_spinetta = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_spinetta,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_spinetta = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_spinetta\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    learning_rate=0.001,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","trainer_spinetta = Trainer(\n","    model=model_spinetta,\n","    args=training_args_spinetta,\n","    data_collator=data_collator_spinetta,\n","    train_dataset=train_dataset_spinetta\n",")\n","\n","trainer_spinetta.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_spinetta = model_spinetta.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458,"referenced_widgets":["b1f07c31858a43ad802fa39900a7ab85","a1b1ef3964604ecfae5468fa3878baf3","45f2898438f24f0ba3a8ec03cbf202fd","0e3c0dbb50b2463b8a1c50ad685c0edb","20c4ffc9702b48bf847b0d49723714f5","d7bbe84122164b3eabdb83b9dfa0bb32","98574df5b55643698428ac1d55399f63","d40853fb70e148fdb7c06997dcf8dc0e","f8bde03c99724520a1519134cc56e2e5","4885103781d34e31846c58147a703d7c","3fc90df28c84481ca42ed724ad9c2017","41669912d33f4a77ba7bf87e3eaa3718","eb4724f1c398485cb9b18804481ef2eb","7567be6b47904cd8b291a144bdcd69ae","ad5386ab0410422daf251217a2e835be","4c106a446b764d33bc7e28f0649578b0","064554a40ead47d2be41a6886144a060","5cd32086b42146dbaac55b13de5607f2","e283ab94af2a4fcd83c31fdecdb4f7e8","7494340a9f074963b13b4023c51e1a5b","69f413d74ccb478298bfa2af7deb0bfe","5775d893713844d6b4126449950430f9","6c1d7565f10d4660a5a96584907a3d52","89a2569ea25f45deacb019d2392e8764","f3169d79a92c427e90d1c53e33a21e3b","19eabafcf7cd4391918e9a9418d9a5ab","7cd8b3b53a1c49c4b51d1444e44226ec","45b6093ac0a94d6fb2a820eeffa46f0a","9eb39184018d43658460a08c5ddfd34e","764e6e533bac44a2bb5686770acbc9d0","e48aff979d294b7f8cf86946c0ee9a73","cd090f0aa0374814b916c13284a89c2a","f32d657a64484049bfbce3efe955e12a","17efce8377404a9c867bd679fc26ac45","64ffbb742478475ab4495f02647cb5d6","fb1d7043ae2c43d29385802958609c9f","515d9b6ec7374345b4e398facfcd9a2b","26aecb05222947baba268cb4016fb4ae","fc04a146e815494086a4f0196c75cab4","100fd813d7da4ce189a7ed0be62cbde2","6dcd435540a94d47b7c9364bd3a311cc","c4b3dee0affd41dba9ab8e29a740a3a7","7a47357be2524be6877c5ce0c90d52a0","bbe5c332d91d4e589b990e975ed834a6","7b2b96b5d9cd4546afa00e0ca335651e","2ea54391747c4f8ba836202ee4a54ec4","079c99bdc359469c8d4a0a4a29056456","090267c0f1844e0892bacad6eb4eb258","47c28ddd159c438b87dff55687168106","4e1b89fa489443c784903975e7cb0d9e","414cd20993b8426b8fbb0a4d1d349faf","1581fc068cc548bbadd30f6d6d6cd589","89aa0856c8584e43be2ba7d34589fd6f","c483372d341a4be5b2aff7ea7d932784","9799ca367e4544ef9e287a58ce2c3b7c","29073456a373495d9f9309888308af75","39c22d199bdb4e0f829de9f749e873cc","db218e7c9527436380d4bbdbe74b6c65","aa704158b8854d95bf1ff5f02e7640fd","09ae1666fedd4e08b2882ded1ca132c9","c4d25b87cca742b7a8b1af5e6dd86fac","97b0351b2c604308a5363ce6a3568e1a","eb1f66127ae64876b4780cfb30c26657","7bbce1489e49446cb5a2fa8be105a978","2713feab3aba409691ed10f4767eb704","33080c272fed4beca86a4616eedbd9c5","162542ca57384ddbb3b11f1228b9970d","032ec9ee6c0e4f608cc1f0ab21de62e7","b688f440101848b6a0a8bd134cad0ade","5c1cbaa9f24a4720a58958873ef8d02e","4cd031d9db914fe389d8c356b5e8e5bb","0f8ddbd561b14147a4f69c91794b5b89","866ee771ea224200a7d47ad1f450a4e1","fa59d916fe1d43098f7b9f5caf2a13f5","ef9e111e6b114221823fb4339b57f45a","c6ab8e5a8f724a16bf0351945a2ebaf4","e2d899b08f1f4099a4347e1400b63624"]},"id":"lKPew8o1tZL4","executionInfo":{"status":"ok","timestamp":1732534119883,"user_tz":180,"elapsed":55281,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"b8a4b92b-b95a-43b1-f035-6b233faa9ca2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f07c31858a43ad802fa39900a7ab85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41669912d33f4a77ba7bf87e3eaa3718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1d7565f10d4660a5a96584907a3d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17efce8377404a9c867bd679fc26ac45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b2b96b5d9cd4546afa00e0ca335651e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29073456a373495d9f9309888308af75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162542ca57384ddbb3b11f1228b9970d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [180/180 00:45, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_spinetta(model_spinetta, tokenizer_spinetta, input_text, max_length=200)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2MERmFn0duf","executionInfo":{"status":"ok","timestamp":1732534130901,"user_tz":180,"elapsed":2852,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"fbf75071-9a47-4f79-cb7e-6933d599cf72"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno el sol\n","y un guerrero no detiene jamás\n","su marcha. Fermín se fue a la vida\n","No corras más\n","Tu tiempo es hoy\n","Y al fin mi duende nació conservar y cuidar con amor este jardín de gente\n","Eterno en el día sin Sol\n","Algún arbol que robé cuidará su boca saldrá\n","Más si tu cielo brisa\n","Cómo haré para ver así ya volver\n","Que ni los sueños living ojaron de llover\n","Sube, saltan por estante\n","\n","Pretenda volviendo canción recirculemente idiota voz le confronto ha de la galaxia\n","\n","La luz\n","Nunca callés ser felicen sus manes respondrir\n"]}]},{"cell_type":"markdown","source":["## Tini"],"metadata":{"id":"Unon8TBE0599"}},{"cell_type":"code","source":["# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 100,\n","    \"callejero\": 0,\n","    \"spinetta\": 0,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas_tini = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_tini.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_tini))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_tini = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_tini = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_tini = TextDataset(\n","    tokenizer=tokenizer_tini,\n","    file_path=\"dataset_train_tini.txt\",\n","    block_size=128\n",")\n","data_collator_tini = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_tini,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_tini = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_tini\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=25,\n","    per_device_train_batch_size=4,\n","    learning_rate=0.001,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_tini = Trainer(\n","    model=model_tini,\n","    args=training_args_tini,\n","    data_collator=data_collator_tini,\n","    train_dataset=train_dataset_tini\n",")\n","\n","trainer_tini.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_tini = model_tini.to(\"cuda\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"QvaPLm1du92V","executionInfo":{"status":"ok","timestamp":1732534465894,"user_tz":180,"elapsed":193083,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"2c7068fa-760e-4067-cfec-74ab9a4fbe70"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 03:10, Epoch 25/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.223000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.044600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["def generar_cancion_tini(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.8,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"11Nbhdf80-xP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_tini.pad_token = tokenizer_tini.eos_token\n","def generar_cancion_tini(model, tokenizer, input_text, max_length=1000):\n","    # Tokenizar el texto de entrada con atención y relleno\n","    inputs = tokenizer(\n","        input_text,\n","        return_tensors=\"pt\",\n","        padding=True,              # Asegura que haya relleno si es necesario\n","        truncation=True,           # Trunca el texto si excede el tamaño máximo\n","        max_length=128             # Tamaño máximo del bloque\n","    )\n","    inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}  # Mover a GPU\n","\n","    # Generar texto\n","    outputs = model.generate(\n","        **inputs,                  # Incluye input_ids y attention_mask\n","        max_length=max_length,     # Longitud máxima del texto\n","        num_return_sequences=1,    # Número de secuencias a generar\n","        temperature=0.5,           # Aleatoriedad en la generación\n","        top_k=100,                  # Considera solo los 50 tokens más probables\n","        top_p=0.9,                 # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,    # Penaliza repeticiones\n","        do_sample=True             # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"],"metadata":{"id":"Y4oiA6pN2jbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_tini(model_tini, tokenizer_tini, input_text, max_length=600)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ziAgzcFi1KJt","executionInfo":{"status":"ok","timestamp":1732484845414,"user_tz":180,"elapsed":10836,"user":{"displayName":"Malena Alamo","userId":"14613785634686341446"}},"outputId":"61946d3b-d206-4f47-c366-1fa4931e9dda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno\n","\n","Porque ahora lo que soy\n","Me encanta este desaire\n","Este es mi último baile (uh)\n","\n","A veces siento que caigo y que vivo importa\n","Ya no se enamora, más fuerte\n","Hasta TINI, TINI esta noche yo soy\n","Dos mil thirty five\n","That's right ya no te puede ver\n","Baby: Baby, yo no te vayas\n","Tini, no te vayas\n","Qué te vayas\n","Los dejé palabras pa' antes, no te vayas\n","\n","Cambiando el Soltará\n","Así en la momento, y tomoëtú neces tús un beso adió\n","Que ya noSi me hace a traició\n","Un viatro¿Por\n","Siembre\n","Ni de tiene y siе extrañas\n","Ay, y sigasa\n","Ah\n","No saben las despе miedo y ya sabaz\n","Nena\n","(¡ngelas\n","Oga, boluda, boluda\n","\n","Vive yo solo invierda fue mi costa rumboemos a tu corazón y ya no te vida\n","Se hombre hasta 90\n","Onlegan\n","Pa' dentro') ¿)</iciste y ahora perdería a travame un trago\n","\n","Estoy a traventura late\n","Guardaré sus mar\n","Corazón trauе invoca\n","Tuvo a ti, trave mi culpa y ahora nos fresa y ahora pa' alimentan contratar\n","(y yo aquí ya peque sabia\n","Algo ya no venir mi mina traovió ya sufridave contra la persiana y ya need andеmpre)\n","\n","La reina\n","En Miami pa' de Moëtadie quiera\n","\n","Muy ya saberito pa' que ya no va a ilus beso fingero\n","\n","Te amigarde y yo\n","\n","\n","El cada tan grande como habla chance pa'\n","Keep a secreta través\n","Yo.com\n","Enga travidad\n","�Parecantas y ahora a volver\n","Llegues ya sabes\n","Steve A olvidarte y hay que ya te confieso combin\n","\n","Debo y ahora ya no te vayan pa'\n","Peque yo\n","Miras mentira y ya vendasa\n","Hay un sueño feliz\n","Acéinticiste y ya no te vaga tu phone\n","\n","\n","\n","Bailando mataran\n","Como yo\n","Cuando ya sabeto\n","Termin\n"]}]},{"cell_type":"markdown","source":["##Dillom\n"],"metadata":{"id":"c1Kq4F7Z1RJt"}},{"cell_type":"code","source":["def generar_cancion_dillom(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"6JaqZat71Xi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 0,\n","    \"spinetta\": 0,\n","    \"dillom\": 100\n","}\n","letras_seleccionadas_dillom = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_dillom.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_dillom))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_dillom = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_dillom = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_dillom = TextDataset(\n","    tokenizer=tokenizer_dillom,\n","    file_path=\"dataset_train_dillom.txt\",\n","    block_size=128\n",")\n","data_collator_dillom = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_dillom,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_dillom = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_dillom\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=20,\n","    learning_rate=0.0005,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_dillom = Trainer(\n","    model=model_dillom,\n","    args=training_args_dillom,\n","    data_collator=data_collator_dillom,\n","    train_dataset=train_dataset_dillom\n",")\n","\n","trainer_dillom.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_dillom = model_dillom.to(\"cuda\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"dtHPSKBowtpp","executionInfo":{"status":"ok","timestamp":1732483473120,"user_tz":180,"elapsed":160629,"user":{"displayName":"Malena Alamo","userId":"14613785634686341446"}},"outputId":"6981536f-2357-4c22-de2c-85ee90400b61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [820/820 02:36, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.153300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_dillom(model_dillom, tokenizer_dillom, input_text, max_length=200)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"NUN9R_mZ6QOK","executionInfo":{"status":"error","timestamp":1732534466876,"user_tz":180,"elapsed":984,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"7ef1760e-6246-43c4-d882-aa907d9c71b4"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'generar_cancion_dillom' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-d8b961ab88e1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Amor eterno\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcancion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerar_cancion_dillom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dillom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_dillom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Canción generada:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'generar_cancion_dillom' is not defined"]}]},{"cell_type":"markdown","source":["## Callejero"],"metadata":{"id":"sZWaEMtQ63pd"}},{"cell_type":"code","source":["def generar_cancion_callejero(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"ne-dnn2869sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 100,\n","    \"spinetta\": 0,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas_callejero = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_callejero.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_callejero))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_callejero = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_callejero = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_callejero = TextDataset(\n","    tokenizer=tokenizer_callejero,\n","    file_path=\"dataset_train_callejero.txt\",\n","    block_size=128\n",")\n","data_collator_callejero = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_callejero,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_callejero = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_callejero\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=15,\n","    learning_rate=0.0005,\n","    per_device_train_batch_size=4,\n","    save_steps=500,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_callejero = Trainer(\n","    model=model_callejero,\n","    args=training_args_callejero,\n","    data_collator=data_collator_callejero,\n","    train_dataset=train_dataset_callejero\n",")\n","\n","trainer_callejero.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_callejero = model_callejero.to(\"cuda\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"3StwQUMa-XSO","executionInfo":{"status":"ok","timestamp":1732483241941,"user_tz":180,"elapsed":180437,"user":{"displayName":"Malena Alamo","userId":"14613785634686341446"}},"outputId":"8f109b5e-0266-4ebd-fd28-09adab8be53f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='840' max='840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [840/840 02:56, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.574500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_callejero(model_callejero, tokenizer_callejero, input_text, max_length=200)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLQYfdky-53T","executionInfo":{"status":"ok","timestamp":1732483252472,"user_tz":180,"elapsed":2656,"user":{"displayName":"Malena Alamo","userId":"14613785634686341446"}},"outputId":"e6a526a1-39cb-45fa-d96d-60a05f4c7c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno y la más cara\n","Nosotros somos los mejores amigos\n","En mi podés confiar\n","No me vengas nada, yo lo que hoy se te re gustar\n","Pero no tienen febrero, por ese 'tán celoso' (na-na) A tu gato ya ni me pongo en el clínico\n","Lo' gato' que toqué así está bellaca pa'l quedar\n","Ella sabe que tiene alta burra conmigo acuerdo\n","Si nos miran, entonce' no me voy rally de espionaje', ah-ah\n","¿Qué? Ah! Alan Gome’\n","Hagan casi past tenemos día anda la resaca en sueltas\n","Yo soy milipili un bueno como cómo jue\n"]}]},{"cell_type":"markdown","source":["## Callejero + Tini"],"metadata":{"id":"-El6HbxmAGJ0"}},{"cell_type":"code","source":["def generar_cancion_tini_callejero(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"7TDMoja4_eax","executionInfo":{"status":"ok","timestamp":1732553588886,"user_tz":180,"elapsed":314,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 100,\n","    \"callejero\": 80,\n","    \"spinetta\": 0,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas_tini_callejero = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_tini_callejero.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_tini_callejero))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_tini_callejero = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_tini_callejero = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_tini_callejero = TextDataset(\n","    tokenizer=tokenizer_tini_callejero,\n","    file_path=\"dataset_train_tini_callejero.txt\",\n","    block_size=128\n",")\n","data_collator_tini_callejero = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_tini_callejero,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_tini_callejero = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_tini_callejero\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    learning_rate=0.001,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_tini_callejero = Trainer(\n","    model=model_tini_callejero,\n","    args=training_args_tini_callejero,\n","    data_collator=data_collator_tini_callejero,\n","    train_dataset=train_dataset_tini_callejero\n",")\n","\n","trainer_tini_callejero.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_tini_callejero = model_tini_callejero.to(\"cuda\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"nEu7cno0ASL5","executionInfo":{"status":"ok","timestamp":1732553765322,"user_tz":180,"elapsed":174582,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"f60b9f5a-760d-47ac-c611-ad86e4a2a79a"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [960/960 02:51, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.345000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_tini_callejero(model_tini_callejero, tokenizer_tini_callejero, input_text, max_length=500)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypoSRdlXGeJ4","executionInfo":{"status":"ok","timestamp":1732553972734,"user_tz":180,"elapsed":5235,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"5acce357-99e9-42b7-827a-07dd29417dc6"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno, uoh\n","Libre soy, libre soy\n","Libertad sin vuelta atrás\n","\n","Y firme así\n","Me quedó aquí\n","No me a ser yo aquí\n","Fua, mi amor\n","Pero solo hay una vida de tu corazón\n","\n","Una vida de frícil (uh)\n","\n","Debo estar loca, no poder salir\n","Nadie sabe que es maldita\n","Hay lo mismo cuando estés triste pensándome en la cama\n","Con su cari de ti te vas a estar con algo\n","No pienso volver el fue tiempo\n","\n","Una vez dice polisé haces hicen parengas más y diga en lo otra hasta\n","\n","\n","Cuando ya segú parengas se encuvia dejes se encender por quierda hermana\n","Sorry, perderte ahora que son hería\n","\n","\n","Y no seas el se encima\n","Si nosotros secuvia se fue ya se fue hermanos\n","Sabe' en las demás\n","Pensando arde las demostrar\n","Pensimos polaridad\n","Para decís dame en más\n","Seguridad acuerdo que el problema sol sub her fin te arribí\n","Algo dejes verdad se enc��nas seguir\n","\n","Tres que encontrás\n","\n","Y si son hermanos seguias por miento que son heridas por los guerí\n","\n","Pude hablan pasamos\n","Y yo nunca arma\n","Son hermela\n","\n","Estoy son heridas caver quién pausa de las manos\n","Recuerdas maños\n","Son heron hermanos y ohaces se encima veces ganas de muy dentro\n","\n","Y sentido\n","\n","Y ahora heridas que me va a todavía se encender\n","Son herman jarra\n","Y no llegar\n","Calma\n","Y no te va a calle\n","Y no que el marihacer para dejar mis besos en piel bienso\n","Y este sentir rafag\n"]}]},{"cell_type":"markdown","source":["## Spinetta + Dillom"],"metadata":{"id":"GDLdj3zhFS7z"}},{"cell_type":"code","source":["def generar_cancion_sd(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"DNFE60ruGsxO","executionInfo":{"status":"ok","timestamp":1732554010413,"user_tz":180,"elapsed":373,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 0,\n","    \"spinetta\": 100,\n","    \"dillom\": 50\n","}\n","letras_seleccionadas_sd = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_sd.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_sd))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_sd = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_sd = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_sd = TextDataset(\n","    tokenizer=tokenizer_sd,\n","    file_path=\"dataset_train_sd.txt\",\n","    block_size=128\n",")\n","data_collator_sd = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_sd,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_sd = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_sd\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    learning_rate=0.001,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_sd = Trainer(\n","    model=model_sd,\n","    args=training_args_sd,\n","    data_collator=data_collator_sd,\n","    train_dataset=train_dataset_sd\n",")\n","\n","trainer_sd.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_sd = model_sd.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"ebgHZqEQGxsd","executionInfo":{"status":"ok","timestamp":1732554419175,"user_tz":180,"elapsed":111892,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"3f7e9c69-871c-4b85-e747-bb087c54eadf"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='590' max='590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [590/590 01:49, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.811500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_sd(model_sd, tokenizer_sd, input_text, max_length=500)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"SAChdA_HG0Ii","executionInfo":{"status":"ok","timestamp":1732554859985,"user_tz":180,"elapsed":6194,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"47aeb4c9-386d-4d9a-9c2b-1972baabefb7"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno y sin ir al dentista\n","Suena un poco a popper con el jarabe, como si me pregunta: Dillom (what?)\n","Huh?\n","Oh (oh)\n","Huh (eh), puta, cojamo' en el trunk\n","Ahora no jodas like Kronk\n","Lo fumamo' en pipa y en bong\n","\n","Puta, cojo gana plata pelotuda del Chaco\n","Buscando la saco cuiden\n","Ahora ni mirarte es Balención\n","Estoy haciendo mucha raya de Avril Lavigne pero y me esperan a mí guita que yo soy le da\n","Me pelearía pa’ que le confiario más pillo ahora está rezan paixao CBDAYRey (holiеro—\n","\n","Los mandamos fucked upan aire el culo pa’ que DMT (ah)\n","\n","\n","\n","Registral, mediodas chico sieto fuck around this city\n","Fuck that bitchesicletad\n","\n","Yo tengo us vayamos coca mi triste (bueno y Claptoniones hallaba ropa por fa, como en Centamario opa reguentó shady times\n","Coserpechado y Claví lili me voy a vez milajesito y naysí cajes desde ser el asterijo fuck Holy\n","Sobreble G20, mm\n","Ella me divién\n","Busqué la tapa parec y no\n","No, comienen y tanto que no me shawty quiero clogger listo muy sexy\n","\n","Tampoco a wacha queje por antesia\n","Antesos como Bapesta (bres\n","For really, budravesignador\n","Vendemigo hay cupco, mm\n","\n","\n","\n","Y tambiene florece o comerme porfa que pedir permiso, mm\n","Fumando Limp Biz\n","\n","Shawty na'Tamos y no detestripa cookie que sepan tu no\n","Nunca el Pouh. Impala decisión sale 13yo en el A$APGestic\n"]}]},{"cell_type":"markdown","source":["##Spinetta+Callejero"],"metadata":{"id":"jliVs-Z-Glej"}},{"cell_type":"code","source":["def generar_cancion_sc(model, tokenizer, input_text, max_length=1000):\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        inputs,\n","        max_length=max_length,          # Longitud máxima del texto\n","        num_return_sequences=1,         # Número de secuencias a generar\n","        temperature=0.5,                # Aleatoriedad en la generación\n","        top_k=50,                       # Considera solo los 50 tokens más probables\n","        top_p=0.9,                      # Nucleus sampling (90% de probabilidad acumulada)\n","        repetition_penalty=1.5,         # Penaliza repeticiones\n","        do_sample=True                  # Habilita muestreo en lugar de usar solo los tokens más probables\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"x3gGebyvJMMh","executionInfo":{"status":"ok","timestamp":1732554891401,"user_tz":180,"elapsed":280,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Configurar los porcentajes\n","distribucion = {\n","    \"tini\": 0,\n","    \"callejero\": 10,\n","    \"spinetta\": 100,\n","    \"dillom\": 0\n","}\n","letras_seleccionadas_sc = seleccionar_datos(df, distribucion)\n","\n","# Guardar las letras seleccionadas en un archivo de texto\n","with open(\"dataset_train_sc.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"\\n\".join(letras_seleccionadas_sc))\n","\n","# 3. Preparar el dataset para el entrenamiento\n","tokenizer_sc = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model_sc = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","train_dataset_sc = TextDataset(\n","    tokenizer=tokenizer_sc,\n","    file_path=\"dataset_train_sc.txt\",\n","    block_size=128\n",")\n","data_collator_sc = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer_sc,\n","    mlm=False\n",")\n","\n","# 4. Configurar y entrenar el modelo\n","\n","training_args_sc = TrainingArguments(\n","    output_dir=\"./gpt2-finetuned_sc\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    learning_rate=0.001,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True,\n","    report_to=\"none\"  # Desactiva W&B\n",")\n","\n","\n","trainer_sc = Trainer(\n","    model=model_sc,\n","    args=training_args_sc,\n","    data_collator=data_collator_sc,\n","    train_dataset=train_dataset_sc\n",")\n","\n","trainer_sc.train()\n","\n","\n","# Mover el modelo a la GPU\n","model_sc = model_sc.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"tTS8_R-bJPR2","executionInfo":{"status":"ok","timestamp":1732555601861,"user_tz":180,"elapsed":124398,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"8d37b1b2-e16a-4e2a-f00c-b477248448ad"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [610/610 02:02, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.728800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["input_text = \"Amor eterno\"\n","cancion = generar_cancion_sc(model_sc, tokenizer_sc, input_text, max_length=500)\n","print(\"Canción generada:\\n\", cancion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHhZ4xkvJQ4p","executionInfo":{"status":"ok","timestamp":1732555961864,"user_tz":180,"elapsed":6068,"user":{"displayName":"Florencia Fontana Walser","userId":"11549532021423417082"}},"outputId":"55f27c3c-0ef5-4b89-89fd-4c5d5293941b"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Canción generada:\n"," Amor eterno\n","Y así verás lo bueno y dulce que es amar. Atentamente\n","La Banda de los Millones, sos re gilidad\n","\n","Yo a tu corazón sola su periplo\n","Su equipo es tan precario como un cielo\n","\n","En el Titán\n","Pa' que hagamos el plan\n","De darnos blam-blan\n","Y llevarte al beat todos gritan juegue desde vivir.\n","\n","Alguien debió conservar con amor este jardín sin mostrarle\n","ya música para rompejo tal vez qué será\n","Que te gusta la roban\n","Lo río será frío será\n","y en la mar evitarme un ponerte\n","y triste estoy solo\n","ya dormido\n","ya canción banderín se destruicio del destruicio\n","la narcaremente hasta secuante podrínate allen el abrio\n","estrarle tendrás flor cancien aquí...na jarra de huele\n"," color\n","frutesenta milipiliatín\n","dale gracios\n","jalen panes que hueco y pelear\n","�ngel que robinado que guerba\n","yo despotro no detenga\n","ver\n","illos salís de pan\n","és que pan\n","yehasta que podemos de mi wachín\n","ge venime mis\n","ya que hoy nacería olvidarlen y arroque sié\n","ys\n","este despierto sonando feliz\n","Sin brisa hojarasca\n","Relojera de paso tiempre bellaca de enero sié\n","Sé que respond\n","Quéctorine’ vo' triste luz\n","Porque si le doy pan\n","Habecido un color\n","¿Dértense?\n","Como sabe que el capitán\n","Este ensaya carrousel alma de diamante\n","\n","Te robé un placeré\n","Y el capitán\n","\n","Sepas recuerdo en la gente lavé\n","Oh-ple\n","Y el ambicionó\n","\n","No tenés que acágrima h\n"]}]},{"cell_type":"markdown","source":["##"],"metadata":{"id":"IexBSvyiGn_H"}}]}